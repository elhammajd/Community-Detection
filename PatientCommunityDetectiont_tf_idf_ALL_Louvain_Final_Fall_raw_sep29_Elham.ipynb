{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31224b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install python-louvain\n",
    "#! pip install python-igraph\n",
    "#! pip install numpy pandas scikit-learn python-igraph\n",
    "#! pip install --upgrade python-igraph\n",
    "#! pip uninstall igraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f353ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfply import *\n",
    "from IPython.display import display\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import create_engine, event\n",
    "\n",
    "conn_str = 'DRIVER={ODBC Driver 17 for SQL Server};SERVER=KVHSQLPC56;DATABASE=AHDA;Trusted_Connection=yes;'\n",
    "conn_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": conn_str})\n",
    "engine = create_engine(conn_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60038653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from community import community_louvain\n",
    "from sqlalchemy import create_engine\n",
    "from igraph import Graph\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph\n",
    "import random\n",
    "\n",
    "class PatientCommunityAnalysis:\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        self.graph2 = None\n",
    "    \n",
    "    def interactions(self):\n",
    "    #add your own query here. For example, for falls, you need to retrieve interactions for all unique patients \n",
    "    #using HF.interactions.\n",
    "        query_dt = ''' \n",
    "            WITH FirstFall AS (\n",
    "       SELECT \n",
    "              Distinct patient_id\n",
    "              ,min([admit_datetime]) as first_fall\n",
    "              ,min(diagnosis_age) as first_fall_age\n",
    "       FROM \n",
    "              Core.acute_care_diagnoses acd\n",
    "       WHERE \n",
    "              diagnosis_type_code NOT IN ('3', '4', '0')\n",
    "              AND SUBSTRING(icd10_code, 1, 3) IN ('W06', 'W07', 'W08', 'W13', 'W14', 'W15', 'W16', 'W17', \n",
    "                                      'X80', 'Y01', 'Y30', 'W00', 'W01', 'W03', 'W04', 'W18', \n",
    "                                      'W10', 'W05')\n",
    "              AND diagnosis_age >= 65\n",
    "       GROUP BY \n",
    "              patient_id\n",
    ")\n",
    "SELECT \n",
    "       i.patient_id, i.service_class_id, i.start_datetime, i.end_datetime\n",
    "FROM \n",
    "       FirstFall\n",
    "INNER JOIN \n",
    "       HF.interactions i ON i.patient_id = FirstFall.patient_id\n",
    "WHERE \n",
    "       i.start_datetime < first_fall\n",
    "AND        \n",
    "        i.service_class_id NOT IN (80,150,152,68)\n",
    "ORDER BY i.patient_id, i.start_datetime\n",
    "        '''\n",
    "        df = pd.read_sql(query_dt, self.engine)\n",
    "        interactions = df[df['service_class_id'].notna()]\n",
    "        #interactions = interactions.dropna() \n",
    "        unique_patients = interactions['patient_id'].unique()\n",
    "       \n",
    "        train_set = interactions[interactions['patient_id'].isin(unique_patients)]\n",
    "        return train_set\n",
    "  \n",
    "    def sequence(self, interactions_df):\n",
    "        df = interactions_df\n",
    "        df = df.astype({\"service_class_id\": str}, errors='raise')\n",
    "        df4 = df.groupby('patient_id')['service_class_id'].agg(' '.join).reset_index()\n",
    "        return df4\n",
    "        \n",
    "    def patients_projection(self, interactions_df):\n",
    "        df = interactions_df.copy()\n",
    "        print(df)\n",
    "\n",
    "        # Ensure patient IDs are strings (if necessary)\n",
    "        df['patient_id'] = df['patient_id'].astype(str)\n",
    "\n",
    "        # **Consistent Patient ID Mapping**\n",
    "        # Sort patient IDs to ensure consistent ordering\n",
    "        unique_patient_ids = sorted(df['patient_id'].unique())\n",
    "        self.patient_id_to_int = {pat_id: idx for idx, pat_id in enumerate(unique_patient_ids)}\n",
    "        self.int_to_patient_id = {idx: pat_id for pat_id, idx in self.patient_id_to_int.items()}\n",
    "\n",
    "        # Map patient IDs to integer indices\n",
    "        df['patient_id_int'] = df['patient_id'].map(self.patient_id_to_int)\n",
    "\n",
    "        result_map = defaultdict(dict)\n",
    "\n",
    "        # Loop over each service and find patients who share the same service\n",
    "        svc_unique = df['service_class_id'].unique()\n",
    "\n",
    "        for svc in svc_unique:\n",
    "            index = df.index[df['service_class_id'] == svc].tolist()\n",
    "            patients = df.loc[index, 'patient_id_int'].unique()\n",
    "\n",
    "            for i in range(len(patients)):\n",
    "                for j in range(i + 1, len(patients)):\n",
    "                    p1, p2 = patients[i], patients[j]\n",
    "                    if p1 < p2:\n",
    "                        result_map[p1][p2] = result_map[p1].get(p2, 0) + 1\n",
    "                    else:\n",
    "                        result_map[p2][p1] = result_map[p2].get(p1, 0) + 1\n",
    "\n",
    "        # Convert the results into a DataFrame with source, target, and weight (shared services)\n",
    "        source, target, weight = [], [], []\n",
    "        for key, neighbors in result_map.items():\n",
    "            for n, w in neighbors.items():\n",
    "                source.append(key)\n",
    "                target.append(n)\n",
    "                weight.append(w)\n",
    "\n",
    "        df3 = pd.DataFrame({'source': source, 'target': target, 'weight': weight})\n",
    "        return df3\n",
    "\n",
    "    def create_graph(self, interactions_df):\n",
    "        # Create patient projection based on shared services\n",
    "        df = self.patients_projection(interactions_df)\n",
    "\n",
    "        # Create an igraph graph using the edges and weights\n",
    "        edges = list(zip(df['source'], df['target']))\n",
    "        weights = df['weight'].tolist()\n",
    "\n",
    "        # Create the graph with the correct number of vertices\n",
    "        num_vertices = len(self.patient_id_to_int)\n",
    "        graph = igraph.Graph(n=num_vertices, edges=edges, directed=False)\n",
    "        graph.es['weight'] = weights\n",
    "\n",
    "        # Set the vertex names to patient IDs\n",
    "        graph.vs['name'] = [self.int_to_patient_id[idx] for idx in range(graph.vcount())]\n",
    "        \n",
    "        self.graph2 = graph\n",
    "        \n",
    "        self.map4 = {idx: pat_id for idx, pat_id in enumerate([self.int_to_patient_id[idx] for idx in range(self.graph2.vcount())])}\n",
    "\n",
    "        self.graph2 = graph\n",
    "\n",
    "    def community_detection_on_patients(self, number_of_iterations=-1):\n",
    "        numberofitterations=number_of_iterations\n",
    "        # first itteration\n",
    "        louvain = self.graph2.community_multilevel(weights=self.graph2.es['weight'], return_levels=False)\n",
    "        pi = []\n",
    "        piI = []\n",
    "\n",
    "        numberofclustures = 0\n",
    "        for i in range(len(louvain)):\n",
    "            component = louvain[i]\n",
    "\n",
    "            if (len(component) > 1):\n",
    "                piI.append(component)\n",
    "\n",
    "        pi.append(piI)\n",
    "        itteration = 1\n",
    "        if numberofitterations==-1:\n",
    "            while True:\n",
    "                piI1 = []\n",
    "                Previous_components = pi[itteration - 1]\n",
    "                for community in pi[itteration - 1]:\n",
    "\n",
    "                    # print(community)\n",
    "                    induced_subgraph = self.graph2.induced_subgraph(list(community))\n",
    "                    louvain1 = induced_subgraph.community_multilevel(weights=induced_subgraph.es['weight'], return_levels=False)\n",
    "                    for i in range(len(louvain1)):\n",
    "                        subgraph = louvain1[i]\n",
    "                        # print(subgraph)\n",
    "                        lst = []\n",
    "                        for maped_vertex in subgraph:\n",
    "                            map = community[maped_vertex]\n",
    "                            lst.append(map)\n",
    "                        # print(lst)\n",
    "                        # print(tuple(lst))\n",
    "\n",
    "                        piI1.append((lst))\n",
    "                pi.append(piI1)\n",
    "                current_components = pi[itteration]\n",
    "                if not current_components > Previous_components:\n",
    "                    break\n",
    "                else:\n",
    "                    itteration += 1\n",
    "        if numberofitterations!=-1:\n",
    "            if numberofitterations == -1:\n",
    "                while True:\n",
    "                    piI1 = []\n",
    "                    Previous_components = pi[itteration - 1]\n",
    "                    for community in pi[itteration - 1]:\n",
    "\n",
    "                        # print(community)\n",
    "                        induced_subgraph = self.graph2.induced_subgraph(list(community))\n",
    "                        louvain1 = induced_subgraph.community_multilevel(weights=induced_subgraph.es['weight'],\n",
    "                                                                         return_levels=False)\n",
    "                        for i in range(len(louvain1)):\n",
    "                            subgraph = louvain1[i]\n",
    "                            # print(subgraph)\n",
    "                            lst = []\n",
    "                            for maped_vertex in subgraph:\n",
    "                                map = community[maped_vertex]\n",
    "                                lst.append(map)\n",
    "                            # print(lst)\n",
    "                            # print(tuple(lst))\n",
    "\n",
    "                            piI1.append((lst))\n",
    "                    pi.append(piI1)\n",
    "                    current_components = pi[itteration]\n",
    "                    if not current_components > Previous_components:\n",
    "                        break\n",
    "                    else:\n",
    "                        itteration += 1\n",
    "\n",
    "\n",
    "            if numberofitterations != -1:\n",
    "                while itteration<numberofitterations:\n",
    "                    piI1 = []\n",
    "                    Previous_components = pi[itteration - 1]\n",
    "                    for community in pi[itteration - 1]:\n",
    "\n",
    "                        # print(community)\n",
    "                        induced_subgraph = self.graph2.induced_subgraph(list(community))\n",
    "                        louvain1 = induced_subgraph.community_multilevel(weights=induced_subgraph.es['weight'],\n",
    "                                                                         return_levels=False)\n",
    "                        for i in range(len(louvain1)):\n",
    "                            subgraph = louvain1[i]\n",
    "                            # print(subgraph)\n",
    "                            lst = []\n",
    "                            for maped_vertex in subgraph:\n",
    "                                map = community[maped_vertex]\n",
    "                                lst.append(map)\n",
    "                            # print(lst)\n",
    "                            # print(tuple(lst))\n",
    "\n",
    "                            piI1.append((lst))\n",
    "                    pi.append(piI1)\n",
    "                    current_components = pi[itteration]\n",
    "                    if not current_components > Previous_components:\n",
    "                        break\n",
    "                    else:\n",
    "                        itteration += 1\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"number of all iterations\",len(pi))\n",
    "        for i in range(len(pi)):\n",
    "            iteration=pi[i]\n",
    "            print(\"number of commmunities in \"+str(i+1)+' '+\"iteration\",len(iteration ))\n",
    "      \n",
    "    \n",
    "       #prevent calling community detection for patients in create table function:\n",
    "       #return pi,map1,map2\n",
    "        self.pi6=pi\n",
    "        \n",
    "        \n",
    "        return self.pi6,self.graph2  \n",
    "    \n",
    "    def create_table_for_patients(self,iteration2=-1):\n",
    "        itteration2=iteration2\n",
    "        if itteration2==-1:\n",
    "            itteration=len(self.pi6)\n",
    "            print(itteration)\n",
    "        if itteration2 !=-1:\n",
    "            itteration=itteration2\n",
    "        weight = []\n",
    "        out_degree=[]\n",
    "        weightd_degree=[]\n",
    "        for j in range(len(self.pi6)):\n",
    "            itteration1 = self.pi6[j]\n",
    "\n",
    "            weightI = []\n",
    "            out_degreeI = list()\n",
    "            weightd_degreeI=[]\n",
    "            for i in range(len(itteration1)):\n",
    "                component = itteration1[i]\n",
    "\n",
    "                subgraph = self.graph2.induced_subgraph(component)\n",
    "                total_degree = self.graph2.strength(component, mode='all', loops=True, weights=\"weight\")\n",
    "                weightd_degreeI.append(total_degree)\n",
    "                lst = list(range(len(component)))\n",
    "                in_degree = subgraph.strength(lst, mode='all', loops=True, weights=\"weight\")\n",
    "                weightI.append(in_degree)\n",
    "                lst2=[]\n",
    "                for item1, item2 in zip(total_degree,in_degree ):\n",
    "                    item = item1 - item2\n",
    "                    lst2.append(item)\n",
    "                out_degreeI.append(lst2) \n",
    "\n",
    "            weight.append(weightI)\n",
    "            out_degree.append(out_degreeI)\n",
    "            weightd_degree.append(weightd_degreeI)\n",
    "\n",
    "\n",
    "        if itteration2==-1:\n",
    "            itteration=len(self.pi6)\n",
    "            #for community id\n",
    "            \n",
    "            self.vertices = []\n",
    "            idd = 1\n",
    "            id = []\n",
    "            age=[]\n",
    "            gender=[]\n",
    "            primary=[]\n",
    "            fsa=[]\n",
    "            n_encounters=[]\n",
    "            n_interactions=[]\n",
    "            first_admit_dt=[]\n",
    "            last_admit_dt=[]\n",
    "            covid_positive=[]            \n",
    "            \n",
    "            for component in self.pi6[itteration - 1]:\n",
    "                for vertex in component:\n",
    "                    v= self.map4.get(vertex)\n",
    "                    self.vertices.append(v)\n",
    "                    id.append(idd)\n",
    "                idd = idd + 1\n",
    "            #for weight\n",
    "            weightt=[]\n",
    "            for component in weight[itteration - 1]:\n",
    "                for degree in component:\n",
    "                    weightt.append(degree)\n",
    "\n",
    "            #for out degree       \n",
    "            out_degree2=[]   \n",
    "            for component in out_degree[itteration - 1]:\n",
    "                  for out_deg in component:\n",
    "                        out_degree2.append(out_deg)\n",
    "\n",
    "           #for weighted degree       \n",
    "            weighted_degree2=[]   \n",
    "            for component in weightd_degree[itteration - 1]:\n",
    "                  for weight_deg in component:\n",
    "                        weighted_degree2.append(weight_deg)             \n",
    "\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            df.insert(loc=0,\n",
    "                      column='patients_id',\n",
    "                      value=self.vertices)\n",
    "          \n",
    "            df.insert(loc=1,\n",
    "                      column='community_id',\n",
    "                      value=id)\n",
    "\n",
    "            df.insert(loc=2,\n",
    "                      column='in_degree',\n",
    "                      value=weightt)\n",
    "            df.insert(loc=3,\n",
    "                        column='out_degree',\n",
    "                        value=out_degree2)\n",
    "\n",
    "            df.insert(loc=4,\n",
    "                        column='weighted_degree',\n",
    "                       value=weighted_degree2)\n",
    "     \n",
    "            return(df)\n",
    "\n",
    "        if itteration2!=-1:\n",
    "            #for id\n",
    "            # idd = 1\n",
    "            # id = []\n",
    "            # for component in self.pi6[itteration - 1]:\n",
    "                # for vertex in component:\n",
    "                    # id.append(idd)\n",
    "                # idd = idd + 1\n",
    "                \n",
    "            self.vertices = []\n",
    "            idd = 1\n",
    "            id = []\n",
    "            age=[]\n",
    "            gender=[]\n",
    "            primary=[]\n",
    "            fsa=[]\n",
    "            n_encounters=[]\n",
    "            n_interactions=[]\n",
    "            first_admit_dt=[]\n",
    "            last_admit_dt=[]\n",
    "            covid_positive=[]\n",
    "         \n",
    "            \n",
    "            for component in self.pi6[itteration - 1]:\n",
    "                for vertex in component:\n",
    "                    v= self.map4.get(vertex)\n",
    "                    self.vertices.append(v)\n",
    "                    '''index = np.where(self.patients.patient_id== v)[0]'''\n",
    "                    id.append(idd)\n",
    "                idd = idd + 1 \n",
    "\n",
    "            #for weight\n",
    "            weightt=[]\n",
    "            for component in weight[itteration - 1]:\n",
    "                for degree in component:\n",
    "                    weightt.append(degree)\n",
    "            df = pd.DataFrame()                   \n",
    "                    \n",
    "                    \n",
    "\n",
    "            #for out degree       \n",
    "            out_degree2=[]   \n",
    "            for component in out_degree[itteration - 1]:\n",
    "                  for out_deg in component:\n",
    "                        out_degree2.append(out_deg)\n",
    "\n",
    "            #for weighted degree       \n",
    "            weighted_degree2=[]   \n",
    "            for component in weightd_degree[itteration - 1]:\n",
    "                 for weight_deg in component:\n",
    "                        weighted_degree2.append(weight_deg)            \n",
    "\n",
    "                        \n",
    "                        \n",
    "\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            df.insert(loc=0,\n",
    "                      column='patients_id',\n",
    "                      value=self.vertices)\n",
    "\n",
    "            \n",
    "            df.insert(loc=1,\n",
    "                      column='community_id',\n",
    "                      value=id)\n",
    "\n",
    "            df.insert(loc=2,\n",
    "                      column='in_degree',\n",
    "                      value=weightt)\n",
    "            df.insert(loc=3,\n",
    "                        column='out_degree',\n",
    "                        value=out_degree2)\n",
    "            \n",
    "\n",
    "\n",
    "            df.insert(loc=4,\n",
    "                        column='weighted_degree',\n",
    "                       value=weighted_degree2)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            return(df)\n",
    "        \n",
    "        \n",
    "    def count_nodes_in_communities(self, iteration=-1):\n",
    "        iteration = iteration if iteration != -1 else len(self.pi6)\n",
    "        nodes_counts = {}\n",
    "        for i in range(iteration):\n",
    "            communities = self.pi6[i]\n",
    "            for j, community in enumerate(communities):\n",
    "                community_id = f\"Community {j+1} (Iteration {i+1})\"\n",
    "                nodes_counts[community_id] = len(community)\n",
    "        return nodes_counts\n",
    "\n",
    "\n",
    "custom_iteration1 = int(input(\"Enter the number of iterations:\"))\n",
    "\n",
    "patient_community_analysis = PatientCommunityAnalysis(engine)\n",
    "interactions_df = patient_community_analysis.interactions()\n",
    "\n",
    "\n",
    "patient_community_analysis.create_graph(interactions_df)\n",
    "\n",
    "communities, graph = patient_community_analysis.community_detection_on_patients(number_of_iterations=custom_iteration1)\n",
    "output_file_path = 'Iteration_Information_Fall.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(\"done!\\n\")\n",
    "    file.write(f\"Number of all iterations: {len(communities)}\\n\")\n",
    "    for iteration_num, community_list in enumerate(communities, start=1):\n",
    "        file.write(f\"Number of communities in iteration {iteration_num}: {len(community_list)}\\n\")\n",
    "\n",
    "custom_iteration2 = int(input(\"Enter your desired iteration:\"))\n",
    "patient_community = patient_community_analysis.create_table_for_patients(iteration2=custom_iteration2)\n",
    "patient_community.to_csv('Patient_Community_Projection_Fall.csv', index=False)\n",
    "print(patient_community)\n",
    "\n",
    "nodes_counts = patient_community_analysis.count_nodes_in_communities(iteration=custom_iteration2)\n",
    "for community_id, node_count in nodes_counts.items():\n",
    "    print(f\"{community_id}: {node_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae6149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
